{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fantajeon/DLPytorch1.2/blob/master/Chapter1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1amU_dj1bdOg",
        "colab_type": "text"
      },
      "source": [
        "# PyTorch 1.2 버전 설치"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32zRrpCKlhwZ",
        "colab_type": "text"
      },
      "source": [
        "Author: Hyeokjune Jeon(fantajeon@gmail.com)\n",
        "\n",
        "Colab을 통하여 작성했으며, 기본적인 패키지들은 설치가 되어있습니다. 예를들면, matplotlib같은 것입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDtTw0uqyGd_",
        "colab_type": "code",
        "outputId": "dd9ed376-426b-4c5f-832d-f3f0c877180b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install -q --upgrade torch==1.2 torchvision==0.4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 748.9MB 24kB/s \n",
            "\u001b[K     |████████████████████████████████| 8.8MB 47.1MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98gNrkT-bHoe",
        "colab_type": "text"
      },
      "source": [
        "PyTorch 버전은 1.2.0 기준입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0KzdZT4yOcN",
        "colab_type": "code",
        "outputId": "13b3a412-535c-454d-fdad-d3360e6e1ac7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import torch\n",
        "torch.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPVxCeWJdmP6",
        "colab_type": "text"
      },
      "source": [
        "차후에 화면에 그래프를 그릴 것이기 때문에 미리 import 해 놓습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIeBQTcWZSeX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfeRT-1ubWLm",
        "colab_type": "text"
      },
      "source": [
        "# 이제 시작해 보겠습니다.\n",
        "이 번은 맛보기입니다. 한번 경험을 통해서 계속해서 개념들을 더해가면서, 딥러닝에 익숙해지도록 해보겠습니다. 많은 부분을 지금 당장 이해하지 않으셔도 됩니다. 바로 보고 이해하신다고 하면, 이미 기존에 기초가 탄탄하셨던 분일 것입니다. 너무 좌절하지 하지 마시고, 천천히 진행해 보겠습니다.\n",
        "\n",
        "## 꼭 알아야할 내용\n",
        "1. $x$,$y$로부터 $w$,$b$를 찾는다.\n",
        "2. 모델은 $y=wx + b$  이다.\n",
        "3. 미분\n",
        "4. Loss 함수와 연관하여 $w$,$b$를 찾는 과정: gradient descent, learning rate, backpropagation(chain rule).\n",
        "\n",
        "나열한 단어들간에 개념 연결입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lf8ra06Cyuj4",
        "colab_type": "text"
      },
      "source": [
        "다음 주어진 x, y 데이터를 근거로 w, b를 찾아라\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZAVys2Oyxv8",
        "colab_type": "text"
      },
      "source": [
        "$$y = wx + b$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7OfjV2ofh1U",
        "colab_type": "text"
      },
      "source": [
        "일반적으로 w, b의 값을 선언할때 값을 지정을 해줘야 합니다. 보통은 random하게 값을 지정해 줍니다. \n",
        "\n",
        "계속 진행하면서 전역변수 x, y, w, b임을 기억해주세요.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvCnX4IIy3TP",
        "colab_type": "code",
        "outputId": "8733aa50-1530-4e90-93ce-cbb62711752b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# dataset\n",
        "x = torch.tensor([0.1, 0.2, 0.3, 0.4, 0.5, 0.6], dtype=torch.float32)\n",
        "y = torch.tensor([15, 25, 40, 55, 65, 66], dtype=torch.float32)\n",
        "# requires_grad=True는 미분 값을 가진다는 것임.\n",
        "w = torch.rand(1, dtype=torch.float32, requires_grad=True)\n",
        "b = torch.rand(1, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# model parameter, w and b\n",
        "def model(x):\n",
        "  return w*x + b\n",
        "\n",
        "pred_y = model(x)\n",
        "print(pred_y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.2815, 0.3271, 0.3726, 0.4182, 0.4638, 0.5094],\n",
            "       grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2QdPkxRI6R9",
        "colab_type": "text"
      },
      "source": [
        "이제 학습할 목표를 설계해야 합니다. x로부터 예측한 pred_y와 관촬된 y의 관계를 정의해야 합니다.\n",
        "여러가지 있지만 지금은 가장 단순한 방법인 두 변수의 오차의 제곱으로 해봅니다. \n",
        "$$L = \\frac{1}{2} \\sum { (\\text{pred_y} - y)^2 } $$를 합니다.\n",
        "보통 여기서 L을 loss 함수라고 합니다. 이 값을 줄이면, 우리가 원하는 w, b값을 정확히 찾을 수 있을 거라고 희망하면서 진행합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PcNi_yAKJAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(pred_y, y):\n",
        "  return 0.5*(pred_y - y).pow(2.0).sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nL_5bt3Kc_-",
        "colab_type": "text"
      },
      "source": [
        "이제 이 것을 미분해서 기울기가 작은쪽으로 가도록 w, b를 천천히 움직여 봅시다. PyTorch에서는 backward() 함수를 호출하여, 이 두 변수의 미분값을 계산합니다. 신기합니다!! 자동으로 미분을 해줍니다. 미분은 무엇일까요? 쉽게 말하면, 어느 한점에서의 미세한 주변의 변화율입니다. 이건 PyTorch가 연산 과정을 내부적으로 다 기록을 해놓고(computation graph칭함), 이 기록의 근거하여 자동으로 미분값을 계산할 수 있습니다. **이 주변의 변화율을 관찰하여 최적의 위치를 찾아가는 여러 방법이 있습니다.** 여기서는 그 중에서 많이 언급하는 **gradient descent** 방법을 소개합니다. 가장 단순한 최적화 기법이며, 앞으로 최적화를 찾는 과정은 여기서부터 개선점이 시작됩니다. 너무 많은 정보는 지금 어려울 수 있으니, 그렇다 치고 넘어갑시다.\n",
        "\n",
        "추가적인 용어를 소개 합니다. Optimization은 최적화를 하는 과정인 일반적인 용어입니다. Optimizer는 최적화를 하는 알고리즘을 칭합니다. 그러면 optimizer를 무엇으로 썼냐? gradient descent 기법을 썼습니다. 이러면 됩니다. 또는 Gradient Descent Optimization Algorithm이렇게 쓰기도 합니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW_J4xq0KNET",
        "colab_type": "code",
        "outputId": "55353ab8-be33-4cd2-c70e-9bf8f77b7775",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "pred_y = model(x)\n",
        "L = loss(pred_y, y)\n",
        "L.backward()\n",
        "print(\"gradient of w\", w.grad)\n",
        "print(\"gradient of b\", b.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gradient of w tensor([-111.6898])\n",
            "gradient of b tensor([-263.6274])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtbsXagHLIAg",
        "colab_type": "text"
      },
      "source": [
        "**Gradient Decendent 방법으로 최적화를 해보자!**\n",
        "$$\\begin{equation} \n",
        "w_{t+1} = w_{t} - \\eta \\frac{\\partial L}{\\partial w} \\\\\n",
        "b_{t+1} = b_{t} - \\eta \\frac{\\partial L}{\\partial b}\n",
        "\\end{equation}$$\n",
        "여기서 t와 t+1은 업데이트 순서입니다. 이것의 의미는 현재 값을 기준으로 미분한 방향에서 L값이 작은 쪽으로 값을 이동합니다. 그리고 $\\eta$는 learning rate라고 합니다. 이번 순서($t$)에서 $w$와  $b$를 얼마만큼 움직여서 오차($L$)를 줄여나갈지 결정해 줍니다. 주의할 점은 너무 크게 또는 작게 $w$와 $b$를 움직이면 학습에 실패할 수 있다.\n",
        "\n",
        "<img width='720px' src='https://fantajeon.github.io/DLPytorch1.2_Materials/images/gradient_descent.svg' />\n",
        "\n",
        "이 learning rate로 한번에 학습을 하지 않는다는 이야기는 반복적으로 적당하게 w,b를 움직이면서 L값을 관촬해야 한다는 것입니다.\n",
        "\n",
        "$\\frac{\\partial L}{\\partial w}$는 $L$과 $w$의 관계를 잘 설명합니다. 예를들어 그림에 근거해서 설명하면 $w_{t}$가 1번 지점에서 $w$가 티끌만큼($\\triangle w$) 오른쪽으로 움직이면, $L$은 증가를 할 것입니다. $w$가 티끌만큼 왼쪽으로 이동시키면, $L$은 감소를 할 것입니다. 이에 반하여 반대로 2번 지점에서는 $w_{t}$ 반대로 움직일 것입니다. 그런데 잘 보시면, $\\triangle w$를 오른쪽 방향으로 고정해보면, $\\triangle L$의 반대 방향으로 $w$를 일관되게 이동하면 됩니다. 그래서 gradient descent할때 마이너를 곱해줍니다.\n",
        "\n",
        "이제 이 비례 관계를 모든 $w$에서 저희는 직접 알고 있다면, $L$의 변화량을 보고, $w$를 움직일 수 있을 것입니다. 그런데 반대로 $L$을 먼저 관찰해야 합니다. 왜 $L$를 먼저 관찰을 할까요? 이유는 예측한 pred_y와 관측된 y의 오차를 $L$로 정의했기 때문입니다. $L$가 주어졌다고 볼 수 있습니다. 저희가 찾는건 $w$이기 때문입니다. 당연히 $L$의 변화가 증가하면, $w$는 왼쪽으로 조금씩 움직이고, $L$의 변화가 감소하면 $w$를 오른쪽으로 조금씩 움직이면 됩니다. 이 $L$과 $w$의 관계를 잘 설명해주는 것이 gradient인 바로 $\\frac{\\partial L}{\\partial w}$입니다.\n",
        "\n",
        "만일 $L$에 오차라면 오차가 줄어드는 쪽으로 $\\frac{\\partial L}{\\partial w}$을 관촬하여 $w$를 움직여 줄 수 있을 겁니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYHDiaDVZWse",
        "colab_type": "text"
      },
      "source": [
        "휴~ 많이 따라 오셨습니다. 이제 하나로 묶어서 L값을 관찰해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26vsCF4dKWg7",
        "colab_type": "code",
        "outputId": "5511327a-712e-4d2b-9fc4-3b0b1c57f1fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "learning_rate = 0.0001\n",
        "\n",
        "for step in range(300000):\n",
        "  # PyTorch는 Dynamic하게 연산을 기록하는 기능 때문에, \n",
        "  # 매번 loop에서 x-->loss-->backward()-->gradient descent를 해줘야 함.\n",
        "  pred_y = model(x)\n",
        "  L = loss(pred_y, y)\n",
        "  L.backward()\n",
        "\n",
        "  # torch.no_grad()는 computation graph에 기록하지 않는다.\n",
        "  with torch.no_grad():\n",
        "    w -= learning_rate * w.grad\n",
        "    b -= learning_rate * b.grad\n",
        "\n",
        "  if step % 10000 == 0:\n",
        "    print(\"Step:{}, L:{:.5}, w={:.3}, b={:.3}, grad(w)={:.3}, grad(b)={:.3}\".format(step, L.item(), w.item(), b.item(), w.grad.item(), b.grad.item()))\n",
        "\n",
        "  w.grad.zero_()\n",
        "  b.grad.zero_()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step:0, L:6914.4, w=0.478, b=0.289, grad(w)=-2.23e+02, grad(b)=-5.27e+02\n",
            "Step:10000, L:646.1, w=28.7, b=35.0, grad(w)=-13.0, grad(b)=4.31\n",
            "Step:20000, L:485.54, w=40.6, b=30.8, grad(w)=-11.0, grad(b)=3.96\n",
            "Step:30000, L:367.89, w=50.8, b=27.1, grad(w)=-9.43, grad(b)=3.39\n",
            "Step:40000, L:281.67, w=59.5, b=24.0, grad(w)=-8.07, grad(b)=2.9\n",
            "Step:50000, L:218.49, w=67.0, b=21.3, grad(w)=-6.91, grad(b)=2.48\n",
            "Step:60000, L:172.2, w=73.4, b=19.0, grad(w)=-5.91, grad(b)=2.13\n",
            "Step:70000, L:138.28, w=78.9, b=17.0, grad(w)=-5.06, grad(b)=1.82\n",
            "Step:80000, L:113.42, w=83.6, b=15.3, grad(w)=-4.33, grad(b)=1.56\n",
            "Step:90000, L:95.202, w=87.6, b=13.9, grad(w)=-3.71, grad(b)=1.33\n",
            "Step:100000, L:81.854, w=91.0, b=12.7, grad(w)=-3.17, grad(b)=1.14\n",
            "Step:110000, L:72.072, w=93.9, b=11.6, grad(w)=-2.72, grad(b)=0.977\n",
            "Step:120000, L:64.902, w=96.5, b=10.7, grad(w)=-2.33, grad(b)=0.839\n",
            "Step:130000, L:59.654, w=98.6, b=9.94, grad(w)=-1.99, grad(b)=0.714\n",
            "Step:140000, L:55.803, w=1e+02, b=9.28, grad(w)=-1.71, grad(b)=0.613\n",
            "Step:150000, L:52.984, w=1.02e+02, b=8.71, grad(w)=-1.46, grad(b)=0.522\n",
            "Step:160000, L:50.915, w=1.03e+02, b=8.22, grad(w)=-1.25, grad(b)=0.45\n",
            "Step:170000, L:49.403, w=1.05e+02, b=7.81, grad(w)=-1.07, grad(b)=0.382\n",
            "Step:180000, L:48.293, w=1.06e+02, b=7.45, grad(w)=-0.918, grad(b)=0.326\n",
            "Step:190000, L:47.478, w=1.06e+02, b=7.15, grad(w)=-0.787, grad(b)=0.278\n",
            "Step:200000, L:46.882, w=1.07e+02, b=6.89, grad(w)=-0.673, grad(b)=0.242\n",
            "Step:210000, L:46.441, w=1.08e+02, b=6.66, grad(w)=-0.573, grad(b)=0.214\n",
            "Step:220000, L:46.122, w=1.08e+02, b=6.47, grad(w)=-0.493, grad(b)=0.178\n",
            "Step:230000, L:45.886, w=1.09e+02, b=6.31, grad(w)=-0.42, grad(b)=0.159\n",
            "Step:240000, L:45.717, w=1.09e+02, b=6.17, grad(w)=-0.361, grad(b)=0.136\n",
            "Step:250000, L:45.592, w=1.09e+02, b=6.05, grad(w)=-0.314, grad(b)=0.107\n",
            "Step:260000, L:45.496, w=1.1e+02, b=5.95, grad(w)=-0.267, grad(b)=0.0942\n",
            "Step:270000, L:45.431, w=1.1e+02, b=5.87, grad(w)=-0.232, grad(b)=0.079\n",
            "Step:280000, L:45.376, w=1.1e+02, b=5.79, grad(w)=-0.192, grad(b)=0.0787\n",
            "Step:290000, L:45.344, w=1.1e+02, b=5.73, grad(w)=-0.173, grad(b)=0.0548\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVtsudlDa8if",
        "colab_type": "text"
      },
      "source": [
        "w는 110근처, b는 5.7 근처에서 찾았습니다. 이제 화면에 그려보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_X1HvHRbEoG",
        "colab_type": "code",
        "outputId": "10d8118e-4954-40e5-e5e5-3162d3687ce4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "# numpy는 공학자들이 많이 쓰는 공학용 계산 framework입니다. PyTorch는 Numpy와 호환이 잘 되도록 설계되었습니다.\n",
        "x_numpy = x.numpy()\n",
        "y_numpy = y.numpy()\n",
        "# 아래에 detach는 연산을 기록하는 graph에서 때낸다. 향후 어떠한 연산을 해도 그래프에 기록되지 않을 것입니다.\n",
        "pred_y = model(x).detach().numpy()  \n",
        "plt.plot(x_numpy,y_numpy,'ro')\n",
        "plt.plot(x_numpy,pred_y,label='Fitted line')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4871f766a0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuohIiPj/W7e3ow3JbU8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZqSaXUQwHGw",
        "colab_type": "text"
      },
      "source": [
        "# Computation Graph란?\n",
        "그래프에 노드에 변수와 에지에 연산의 개념을 연결시켜서, 입력 변수들이 어떠한 복잡한 계산 과정거치면서 출력 변수까지 연결되어 있는지 기록되어 있는 자료구조입니다. \n",
        "보통 두 과정으로 분류 합니다.\n",
        "1. forward 과정: 이러한 과정을 입력에서 출력까지 그래프 계산하는 과정을 모두 기억을 한다.\n",
        "2. backward 과정: 기억한 모든 과정을 역순서로 미분 관점에서 전파한다. 특히 오차(Loss)에 근거하여 chain rule이 자동으로 적용된 미분값 계산합니다. 이건 backpropagation algorithm 으로 알려져 있습니다. 이 과정을 통해서 learning rate와 함께 병합하여 학습이 진행됩니다.\n",
        "\n",
        "이렇게 모든 과정을 기록하고 기본 제공 연산들에 미분을 미리 계산해놨기 때문에, 계산 과정을 단순히 기록한 computation graph를 통하여 pytorch는 chain rule이 적용된 자동 미분이 가능해집니다.\n",
        "\n",
        "결국 사전에 언급한 gradient descent에서 미분값이 자동으로 계산됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwEuMMTC-5AR",
        "colab_type": "text"
      },
      "source": [
        "## Chain Rule을 품은 Computation Graph기반 Backpropagation의 관계\n",
        "\n",
        "![Computation Graph](https://fantajeon.github.io/DLPytorch1.2_Materials/images/Chain%20Rules%20-%20Computation%20Graph.svg)\n",
        "이 그림은 이해를 돕기위해서 한 개의 $x$, $y$의 샘플을 가지고 Computation Graph를 표현한 것입니다. 초록색은 학습할 변수 노드이고, <span style=\"color:blue\">파란색 노드</span>는 주어진 상수입니다. 그리고 붉은색 $L$노드는 학습 오차량입니다. 왼쪽에서 오른쪽으로 진행하면 forward 과정(곱하기 > 더하기 > 빼기 > 제곱)이고, 오른쪽에서 왼쪽으로 가면 backward 과정입니다. \n",
        "\n",
        "### $w$에서 $L$까지 연결\n",
        "현재까지 언급한 Loss인 $L=(y-\\hat {y})^2$에서 $w$를 학습하기 위해서는 $\\frac{\\partial L}{\\partial w}$을 반듯이 계산해야 합니다. 그런데, $w$와 $L$은 직접적인 연관이 없습니다. 여러 단계의 합성과정을 거친 결과($L$)입니다. 그럼 두 변수를 어떻게 연관을 지을까요? 바로 정답은 편미분방정식의 chain rule에 있습니다. Chain Rule은 각 단계별로 변화량을 누적시킨 과정이라고 볼 수 있습니다. $w$부터 여러단계를 거쳐서 $L$까지 이루어 진 것에 chain rule을 적용하면, $$\\frac{\\partial L}{\\partial w} =  \\frac{\\partial z}{\\partial w} \\frac{\\partial \\hat{y}}{\\partial z}   \\frac{\\partial e}{\\partial \\hat{y}} \\frac{\\partial L}{\\partial e}$$ 이렇게 계산됩니다. 위에 그림처럼 붉은색부터 보라색 점선을 따라서 곱하면 Chain Rule과 동일합니다. 이 처럼 Computation Graph를 근거로 단순한 과정을 반복하면 됩니다. 각각의 미분값은 실체화가 되면, 실제적인 값들로 구체화가 됩니다. \n",
        "\n",
        "이로써 찾고자 하는 변수 $w$와 $b$를 $L$값의 변화량을 보고 움직이는 방향을 결정할 수 있습니다. 그러면 최적값을 찾아가도록 할 수 있을 것입니다.\n",
        "\n",
        "### $w$의 Chain Rule속의 $\\frac{\\partial Y}{\\partial X}$꼴 구체화 해보기\n",
        "각각의 Computation Graph차원에서 잘게 쪼개서 공식을 세워보면 다음과 같습니다:\n",
        "$$z = xw$$\n",
        "$$\\hat {y} = z + b$$\n",
        "$$e = y - \\hat{y}$$\n",
        "$$L = e^2$$\n",
        "\n",
        "그리고 이것을 미분해보겠습니다.\n",
        "$$\\frac{\\partial z}{\\partial w} =x$$\n",
        "$$\\frac{\\partial \\hat{y}}{\\partial z}=1$$\n",
        "$$\\frac{\\partial e}{\\partial \\hat{y}} = -1$$\n",
        "$$\\frac{\\partial L}{\\partial e} = 2e$$\n",
        "$$\\frac{\\partial L}{\\partial L} = 1$$\n",
        "\n",
        "자 이제 Chain Rule로 계산된 값을 각각 교체해 보겠습니다. 그러면 다음과 같이 계산됩니다.\n",
        "$$ \\frac{\\partial L}{\\partial w} = (x)(1)(-1)(2e)(1)=-x(y-\\hat{y})$$\n",
        "이 공식에서보면 $e$값은 <span style=\"color:red\">마지막 계산 예측한 값과 실제값의 오류</span>로 볼 수가 있습니다. 이 오류($e$)가 학습하려는 모델인 $wx + b$에서 입력값 중에 하나인 $x$를 곱하여 만들어 진것으로 볼 수 있습니다. \n",
        "\n",
        "<b>Computation Graph에서 오른쪽 맨 끝에 오류가 왼쪽의 입력단에 $w$까지 전파된 것을 볼 수 있습니다.</b>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a63M9J0d6hF6",
        "colab_type": "text"
      },
      "source": [
        "다음에 더 자세한 이야기(Tensor, Numpy, Deep learning 등)를 진행해 보겠습니다. 오늘은 이 정도까지 정리해보겠습니다.\n",
        "\n",
        "**감사합니다.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7nrWIAwGCiu",
        "colab_type": "text"
      },
      "source": [
        "#전체 코드입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyPUq26GGGaj",
        "colab_type": "code",
        "outputId": "9c833a8a-0544-4885-869d-1797529fc4c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# dataset\n",
        "x = torch.tensor([0.1, 0.2, 0.3, 0.4, 0.5, 0.6], dtype=torch.float32)\n",
        "y = torch.tensor([15, 25, 40, 55, 65, 66], dtype=torch.float32)\n",
        "w = torch.rand(1, dtype=torch.float32, requires_grad=True) \n",
        "b = torch.rand(1, dtype=torch.float32, requires_grad=True)  \n",
        "\n",
        "# model parameter, w and b\n",
        "def model(x):\n",
        "  return w*x + b\n",
        "\n",
        "def loss(pred_y, y):\n",
        "  return 0.5*(pred_y - y).pow(2.0).sum()\n",
        "\n",
        "learning_rate = 0.0001\n",
        "\n",
        "for step in range(300000):\n",
        "  pred_y = model(x)\n",
        "  L = loss(pred_y, y)\n",
        "  L.backward()\n",
        "\n",
        "  # torch.no_grad()는 computation graph에 기록하지 않는다.\n",
        "  with torch.no_grad():\n",
        "    w -= learning_rate * w.grad\n",
        "    b -= learning_rate * b.grad\n",
        "\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "  if step % 10000 == 0:\n",
        "    print(\"Step:{}, L:{:.5}, w={}, b={}\".format(step, L.item(), w.item(), b.item()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step:0, L:6971.0, w=0.45594438910484314, b=0.052840039134025574\n",
            "Step:10000, L:645.41, w=28.716516494750977, b=34.99995040893555\n",
            "Step:20000, L:485.04, w=40.638580322265625, b=30.76883316040039\n",
            "Step:30000, L:367.52, w=50.83012771606445, b=27.10689926147461\n",
            "Step:40000, L:281.4, w=59.55449676513672, b=23.972261428833008\n",
            "Step:50000, L:218.3, w=67.02281951904297, b=21.2889404296875\n",
            "Step:60000, L:172.05, w=73.41553497314453, b=18.991920471191406\n",
            "Step:70000, L:138.17, w=78.88744354248047, b=17.02570343017578\n",
            "Step:80000, L:113.34, w=83.57166290283203, b=15.342569351196289\n",
            "Step:90000, L:95.145, w=87.58219146728516, b=13.901728630065918\n",
            "Step:100000, L:81.811, w=91.01476287841797, b=12.668384552001953\n",
            "Step:110000, L:72.041, w=93.9530029296875, b=11.612641334533691\n",
            "Step:120000, L:64.88, w=96.4686050415039, b=10.70898151397705\n",
            "Step:130000, L:59.637, w=98.61956787109375, b=9.935419082641602\n",
            "Step:140000, L:55.791, w=100.4631118774414, b=9.273345947265625\n",
            "Step:150000, L:52.975, w=102.03907012939453, b=8.706649780273438\n",
            "Step:160000, L:50.909, w=103.39045715332031, b=8.221569061279297\n",
            "Step:170000, L:49.398, w=104.5435791015625, b=7.806668758392334\n",
            "Step:180000, L:48.289, w=105.53205108642578, b=7.451472282409668\n",
            "Step:190000, L:47.475, w=106.37940979003906, b=7.146887302398682\n",
            "Step:200000, L:46.88, w=107.1029281616211, b=6.887559413909912\n",
            "Step:210000, L:46.44, w=107.72865295410156, b=6.664024353027344\n",
            "Step:220000, L:46.121, w=108.25650787353516, b=6.473110198974609\n",
            "Step:230000, L:45.885, w=108.71377563476562, b=6.30997896194458\n",
            "Step:240000, L:45.716, w=109.09524536132812, b=6.17264461517334\n",
            "Step:250000, L:45.592, w=109.42045593261719, b=6.054054260253906\n",
            "Step:260000, L:45.495, w=109.71687316894531, b=5.948074817657471\n",
            "Step:270000, L:45.431, w=109.94575500488281, b=5.865485191345215\n",
            "Step:280000, L:45.376, w=110.17463684082031, b=5.785323143005371\n",
            "Step:290000, L:45.344, w=110.33153533935547, b=5.726433277130127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6N3Ls3afG6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}